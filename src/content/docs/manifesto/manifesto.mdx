---
title: The C# Reinforcement Learning Revolution - Breaking Free from Python's Grip
description: Why C# is superior to Python for reinforcement learning in production environments
---

The question comes relentlessly: "Why build reinforcement learning in C#?" Behind this query lies an unspoken assumption that serious machine learning happens exclusively in Python. This perspective reveals a fundamental disconnect between academic ML researchers with their sprawling Python scripts and those of us solving real industrial problems.

I developed RLMatrix not as an ML researcher but as a practitioner with concrete problems to solve. I find it maddening when Python ecosystem devotees presume to understand my requirements better than I do. This isn't about language preferences—it's about recognizing that production environments demand different tools than research notebooks.

## Real-World Problems Demand Real Solutions

My journey began with microfluidic device design. For my PhD in the deMello group, I needed to optimize complex fluidic structures beyond what manual prototyping could reasonably achieve.

<div style="background-color: white; padding: 10px; display: inline-block;">
    <img src="/images/manifesto/wafer.jpg" alt="Microfluidic wafer" />
</div>

*Microfluidic chips require master molds fabricated in cleanroom conditions—each prototype representing hours of meticulous labor.*

Creating and testing these devices is prohibitively expensive. Even minor fabrication variations can render an entire design useless. Computational fluid dynamics simulation offered a path forward, but presented a new challenge: connecting CFD outcomes to reinforcement learning systems.

My challenge quickly proved more demanding than toy problems like CartPole. With partially observable dynamics and complex reward structures, I needed to modify standard algorithms substantially.

My project worked with a pipeline containing many external software packages manipulating large amounts of data. Nearly all this software provided robust C# SDKs, making C# the natural choice for orchestrating the overall system. Initially, I tried maintaining Python/MATLAB interop for the reinforcement learning components, but this became increasingly unsustainable as my algorithmic modifications grew.

## The Debugging Revolution

:::tip[The Debugging Edge]
With RLMatrix, engineers can trace execution through the entire reinforcement learning loop, set breakpoints anywhere, and inspect all variables and tensors. This visibility is impossible with Python/C# translation boundaries.
:::

This revealed the first critical advantage of unifying development in C#: comprehensive debugging. Consider a manufacturing facility deploying reinforcement learning for robotic control—they'll inevitably need to adapt published algorithms for their specific context. With RLMatrix, engineers can trace execution through the entire reinforcement learning loop, set breakpoints anywhere, and inspect all variables and tensors.

Traditional approaches make this nearly impossible. ML-Agents introduces a Python/C# translation boundary precisely where visibility is most crucial. Other frameworks offer "black box" algorithms accessed via socket connections, with minimal transparency into internal operations. This approach isn't just inconvenient—it's fundamentally inadequate for industrial applications, like hitching modern factory equipment to horse-drawn carriages.


What began as a practical solution revealed transformative capabilities I hadn't anticipated.
### Universal Compatibility

Unlike framework-specific implementations, RLMatrix works with any C# API. With support for both modern .NET and .NET Standard 2.0, it runs everywhere from cloud services to Unity games. More importantly, it enables seamless transitions between development and distributed deployment:

```csharp
// Local development agent
var agent = new LocalContinuousRolloutAgent<float[]>(optsppo, env);

// Deploy to compute cluster - one line change
var agent = new RemoteContinuousRolloutAgent<float[]>("http://127.0.0.1:5006/rlmatrixhub", optsppo, env);
```

:::note[Deploy Anywhere]
Develop locally, then scale to distributed compute resources with a single line change. No rewriting, no refactoring - the same code works everywhere.
:::

<div style="background-color: white; padding: 10px; display: inline-block;">
    <img src="/images/manifesto/sharedalgo.png" alt="Local algorithm" />
</div>

*Local training architecture*

<div style="background-color: white; padding: 10px; display: inline-block;">
    <img src="/images/manifesto/distributedalgo.png" alt="Remote algorithm" />
</div>

*Distributed training architecture*

This isn't just convenient—it eliminates an entire class of deployment problems. Develop locally, then scale to distributed compute resources without rewriting or refactoring your implementation.

### Performance That Matters

The performance characteristics startled me. RLMatrix collects experiences asynchronously while the core engine processes batches, then vectorizes them for parallel GPU execution. This substantially outperforms the traditional approach of processing experiences sequentially.

Python's fundamental limitation becomes unavoidable in reinforcement learning: it's excellent at delegating vectorized operations to C++ libraries but painfully slow for everything else. Reinforcement learning involves massive data manipulation outside these optimized paths—precisely where Python falters.

RLMatrix achieved exceptional performance with minimal optimization effort. Basic threading patterns combined with the JIT compiler's capabilities created a system that dramatically outperforms specialized Python frameworks without sacrificing flexibility.

<div style="background-color: white; padding: 10px; display: inline-block;">
    <img src="/images/manifesto/stats.jpg" alt="Performance comparison" />
</div>

*RLMatrix consistently outperforms both ML-Agents and Godot RL Agents across in time-per step in identical environments in real-time.*

### Type Safety as a Superpower

:::caution[Runtime vs. Compile Time]
Python discovers critical errors during runtime—often after hours of training. C# catches these same issues during compilation, before you've wasted any compute resources.
:::

The type safety advantage becomes crucial in complex environments:

```python
# Python: Dimension errors, type mismatches, and range violations
# discovered only at runtime—possibly after hours of training
def step(self, actions):
    for motor, action in zip(self.motors, actions):
        motor.apply_torque(action)
```

```csharp
// C#: Constraints verified at compile time
// Impossible to pass incorrect shapes, types, or ranges
[RLMatrixActionContinuous(-1, 1)]
public void ControlJoint1(float torque) {
    joint1.ApplyTorque(torque);
}

[RLMatrixActionContinuous(-1, 1)]
public void ControlJoint2(float torque) {
    joint2.ApplyTorque(torque);
}
```

## Beyond ML-Agents

:::note[Beyond ML-Agents]
RLMatrix implements algorithm variants like full DQN Rainbow that ML-Agents simply cannot offer, while working across the entire .NET ecosystem rather than just Unity.
:::

Let's be clear about RLMatrix's capabilities compared to established solutions like ML-Agents. RLMatrix implements a comprehensive algorithm suite that ML-Agents simply cannot match, including full DQN Rainbow variants with prioritized experience replay, noisy networks, and distributional RL. These aren't academic curiosities—they're powerful tools that can mean the difference between success and failure in challenging environments.

More importantly, RLMatrix isn't limited to a single framework. While ML-Agents serves only Unity, RLMatrix works across the entire .NET ecosystem—from ASP.NET backends to Godot game development to industrial control systems. This universality eliminates specialized knowledge requirements and fragmented implementations across your technology stack.

The team behind ML-Agents includes brilliant engineers—you can read their excellent paper [here](https://arxiv.org/abs/1809.02627). Their work represents the best possible outcome within the constraints they accepted. But that's precisely the problem—they began with a fundamental architectural compromise that no amount of engineering brilliance could overcome.

A solo developer with a superior technical foundation outpaced a specialized team not through extraordinary skill, but by rejecting unnecessary constraints. The lesson is clear: choosing the right foundation matters more than team size or budget.

## The Transparency Advantage

When engineers encounter issues with Python-based reinforcement learning systems, they face a bewildering array of abstraction layers. Is the problem in their environment code? The Python RL framework? The C++ numerical libraries? The interop layer? Locating and fixing issues becomes a specialized skill in itself.

RLMatrix eliminates this complexity. Engineers see the complete system—from environment simulation to neural network updates—in a single, consistent language with unified debugging tools. This isn't just about convenience; it fundamentally changes who can successfully deploy reinforcement learning.

With traditional approaches, companies need specialized ML engineers who understand the entire fragmented stack. With RLMatrix, any competent C# developer can understand, modify, and extend reinforcement learning systems. This democratization turns reinforcement learning from an esoteric specialty into a standard tool in the developer toolkit.

The educational value extends beyond professional developers. Students and researchers can trace algorithm execution step-by-step, building genuine understanding rather than treating components as magical black boxes. This transparency accelerates both learning and innovation.

## The Source Generation Revolution

Perhaps the most transformative aspect of RLMatrix is how it reshapes the development workflow through C# source generators. Traditional reinforcement learning development follows a tortuous path:

1. Define environment logic
2. Manually implement interfaces with boilerplate code
3. Handle observation space and action space definitions
4. Connect environment to learning algorithm
5. Debug interface mismatches when things inevitably break

The RLMatrix Toolkit eliminates steps 2-4 entirely. Simply annotate your domain code with attributes:

```csharp
[RLMatrixEnvironment]
public partial class IndustrialController
{
    [RLMatrixObservation]
    public float GetTemperature() => sensor.CurrentTemperature;
    
    [RLMatrixActionContinuous(-100, 100)]
    public void SetHeatingPower(float power) {
        heater.ApplyPower(power);
    }
    
    [RLMatrixReward]
    public float CalculateEfficiency() {
        return MeasureProcessEfficiency();
    }
}
```

The source generator automatically produces all necessary connecting code, with compile-time verification of your entire reinforcement learning pipeline. This isn't just less code—it's a fundamentally different approach to the problem that keeps you focused on domain logic rather than RL infrastructure.

Python persists in machine learning not because of technical merit, but through ecosystem inertia and academic tradition. Its limitations are increasingly evident as reinforcement learning moves from research papers to production systems. The dynamically-typed, interpreter-dependent approach makes sense for quick prototyping but becomes actively harmful when reliability and performance matter.

C# provides exactly what production reinforcement learning demands: performance approaching C++, type safety that catches errors before deployment, consistent debugging tools, and modern language features that boost developer productivity. RLMatrix proves that we can implement state-of-the-art algorithms without drowning in boilerplate or performance hacks.

## Join the Revolution

The status quo isn't sustainable. Organizations are discovering the hard way that Python-based reinforcement learning systems crack under production pressures. They demand specialized knowledge to maintain, resist integration with existing systems, and introduce runtime errors that could have been caught at compile time.

:::tip[Fair Licensing]
Non-commercial or low income users get full MIT license terms. I've committed to transitioning the entire project to MIT once licensing agreements and donations reach $300,000 USD—a fraction of what organizations invest in less effective alternatives.
:::

As an independent developer committed to changing this paradigm, I've created RLMatrix with a practical dual licensing model. Non-commercial or low income users get full MIT license terms, while commercial applications support continued development. I've committed to transitioning the entire project to MIT once licensing agreements and donations reach $300,000 USD—a fraction of what organizations invest in less effective alternatives.

If you're directing AI initiatives involving reinforcement learning, consider the hidden costs of the Python approach:
- Development time lost to debugging cross-language interfaces
- Performance penalties from interpreted code and GIL limitations
- Deployment complexity when integrating with production systems
- Specialized personnel required for maintenance and modifications
- Runtime errors that could have been prevented at compile time

Production systems deserve tools designed for reliability and performance, not academic prototypes stretched beyond their capabilities. RLMatrix offers a path forward—combining algorithmic sophistication with industrial-strength engineering.

Break free from Python's grip. Join the RLMatrix revolution.

:::danger[Addressing Python Absolutism]
<details>
    <summary>Click to expand responses to common Python arguments</summary>

    **"But Python is easier! Just import a couple libraries and you're done!"**

    Let's address this common refrain head-on. This simplistic view fundamentally misunderstands reinforcement learning development. DRL isn't like importing scikit-learn and calling `model.fit()`. It requires substantial custom code, environment design, reward engineering, and algorithm modification.

    The "few lines of code" argument collapses entirely for production applications. You'll inevitably need to integrate with existing systems, handle edge cases, optimize performance bottlenecks, and debug complex interaction patterns. In these scenarios, Python's initial convenience transforms into technical debt.

    Ironically, the library ecosystem argument favors C#, not Python, for many domains. Game engines, industrial control systems, and enterprise software predominantly expose C# APIs, not Python ones. That's why major engines like Unity and Godot offer C# as a first-class language. The entire .NET ecosystem provides rich libraries for everything from image processing to signal analysis—all with compile-time type safety.

    **"But Python with NumPy/PyTorch is faster than C#!"**

    This reveals a fundamental misunderstanding of reinforcement learning workloads. Yes, Python delegates heavy tensor operations to C++ libraries, but reinforcement learning involves substantial computation *outside* these optimized paths—precisely where Python's interpreter and GIL become crippling bottlenecks.

    The inconvenient truth? In reinforcement learning, you cannot vectorize all operations. Trajectory sampling, environment interaction, experience replay management, and numerous other critical components happen in Python's slow execution environment. These bottlenecks can't be eliminated by mumbling "NumPy" like a magic incantation.

    When confronted with this reality, Python defenders often retreat to: "Well, you could just write the slow parts in C++..." At that point, you're acknowledging Python is the problem! Why not use a language that's both productive *and* performant, rather than managing two codebases with complex interoperability?

    RLMatrix's performance advantages aren't theoretical—they're measured and documented. The benchmarks don't lie. C# with TorchSharp delivers exceptional performance exactly where Python struggles most, while maintaining development velocity and code clarity.

    **"But Python has a much larger ML community and more documentation!"**

    This might be the purest example of cargo cult thinking in machine learning. It assumes that more documentation automatically means better solutions for your specific problem.

    The reality? Most Python ML documentation focuses on supervised learning, not reinforcement learning. Quantity doesn't equal quality—much of what exists is contradictory, outdated, or covers only toy examples.

    Understanding one well-designed, coherent C# codebase provides more value than piecing together solutions from dozens of inconsistent Python libraries. And if you truly need a specific algorithm, you can still interface with Python code when necessary.

    Choosing Python solely because "that's what everyone uses" is the "nobody ever got fired for buying IBM" of machine learning—prioritizing crowd behavior over engineering efficiency.

    The choice is clear: continue struggling with Python's inherent limitations in DRL, or embrace a platform designed for the production requirements you actually have.
</details>
:::
---

*This manifesto was written by the creator of RLMatrix, advocating for a future where reinforcement learning is accessible, performant, and fully integrated with production software ecosystems.*